{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-06T08:21:44.227737Z",
     "iopub.status.busy": "2024-11-06T08:21:44.226874Z",
     "iopub.status.idle": "2024-11-06T08:21:44.244374Z",
     "shell.execute_reply": "2024-11-06T08:21:44.243457Z",
     "shell.execute_reply.started": "2024-11-06T08:21:44.227695Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Integrity_Impact_best_catboost_model.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Impact_Score_xgb_regressor.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/accessVector_best_catboost_model.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Availability_Impact_best_catboost_model.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Availability_Impact_label_encoder.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Exploitability_Score_xgb_regressor.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Access_Complexity_label_encoder.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Integrity_Impactt_label_encoder.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Access_Complexity_best_catboost_model.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Confidentiality_Impact_best_catboost_model.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Confidentiality_Impact_label_encoder.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/Access_Vector_label_encoder.pkl\n",
      "/kaggle/input/final_ml_models/scikitlearn/default/1/BASE_SCORE_xgb_regressor.pkl\n",
      "/kaggle/input/cve-dataset-with-embedding/merged_cve_data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:21:45.830978Z",
     "iopub.status.busy": "2024-11-06T08:21:45.830252Z",
     "iopub.status.idle": "2024-11-06T08:22:10.786519Z",
     "shell.execute_reply": "2024-11-06T08:22:10.785299Z",
     "shell.execute_reply.started": "2024-11-06T08:21:45.830942Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from xgboost) (1.14.1)\n",
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.10/site-packages (4.2.0)\n",
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (1.2.7)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm) (1.14.1)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from catboost) (3.7.5)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost) (8.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost\n",
    "!pip install lightgbm catboost torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:22:29.620222Z",
     "iopub.status.busy": "2024-11-06T08:22:29.619272Z",
     "iopub.status.idle": "2024-11-06T08:22:48.110639Z",
     "shell.execute_reply": "2024-11-06T08:22:48.109769Z",
     "shell.execute_reply.started": "2024-11-06T08:22:29.620167Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\pradeep dubey\\.vscode\\extensions\\ms-python.python-2024.20.0-win32-x64\\python_files\\python_server.py\", line 130, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"<string>\", line 2, in <module>\n",
       "  File \"C:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 912, in read_csv\n",
       "    return _read(filepath_or_buffer, kwds)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 577, in _read\n",
       "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1407, in __init__\n",
       "    self._engine = self._make_engine(f, self.engine)\n",
       "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File \"C:\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\", line 1661, in _make_engine\n",
       "    self.handles = get_handle(\n",
       "                   ^^^^^^^^^^^\n",
       "  File \"C:\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py\", line 859, in get_handle\n",
       "    handle = open(\n",
       "             ^^^^^\n",
       "FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/cve-dataset-with-embedding/merged_cve_data.csv'\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'C:\\Users\\pradeep dubey\\Desktop\\NLP_Project\\Data\\merged_cve_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:22:51.432340Z",
     "iopub.status.busy": "2024-11-06T08:22:51.431889Z",
     "iopub.status.idle": "2024-11-06T08:22:51.530624Z",
     "shell.execute_reply": "2024-11-06T08:22:51.529594Z",
     "shell.execute_reply.started": "2024-11-06T08:22:51.432300Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CVE_ID', 'ASSIGNER', 'Published_Date', 'Last_Modified_Date',\n",
       "       'Impact_Score', 'Access_Vector', 'Access_Complexity', 'Configurations',\n",
       "       'Reference_Data', 'Year',\n",
       "       ...\n",
       "       '759', '760', '761', '762', '763', '764', '765', '766', '767',\n",
       "       'Description'],\n",
       "      dtype='object', length=784)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:23:05.365537Z",
     "iopub.status.busy": "2024-11-06T08:23:05.364860Z",
     "iopub.status.idle": "2024-11-06T08:23:05.557966Z",
     "shell.execute_reply": "2024-11-06T08:23:05.556981Z",
     "shell.execute_reply.started": "2024-11-06T08:23:05.365496Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107087, 768)\n",
      "(107087,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Assuming 'df' is your DataFrame with all the columns\n",
    "# Define columns to exclude\n",
    "columns_to_exclude = [\n",
    "    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n",
    "    'Published_Date', 'Last_Modified_Date', \n",
    "    'Access_Vector', 'Access_Complexity', \n",
    "    'Configurations', 'Reference_Data',\n",
    "    'Year', 'Base_Score', 'Exploitability_Score', \n",
    "    'Confidentiality_Impact', 'Integrity_Impact', \n",
    "    'Availability_Impact'\n",
    "]\n",
    "\n",
    "# Separate the target variable\n",
    "y = df['Impact_Score']  # Your target variable\n",
    "\n",
    "# Select all columns except the excluded ones\n",
    "X = df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Check shapes\n",
    "print(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\n",
    "print(y.shape)  # Should show (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:23:06.002428Z",
     "iopub.status.busy": "2024-11-06T08:23:06.001600Z",
     "iopub.status.idle": "2024-11-06T08:23:16.730423Z",
     "shell.execute_reply": "2024-11-06T08:23:16.729361Z",
     "shell.execute_reply.started": "2024-11-06T08:23:06.002381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost GPU Metrics:\n",
      "MSE: 1.1454, MAE: 0.7909, R²: 0.4984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "# X, y = ... (Load your features and target variable)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost Regressor with GPU\n",
    "xgb_regressor_gpu = xgb.XGBRegressor(tree_method='gpu_hist', gpu_id=0)\n",
    "xgb_regressor_gpu.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate XGBoost\n",
    "y_pred_xgb_gpu = xgb_regressor_gpu.predict(X_test)\n",
    "mse_xgb_gpu = mean_squared_error(y_test, y_pred_xgb_gpu)\n",
    "mae_xgb_gpu = mean_absolute_error(y_test, y_pred_xgb_gpu)\n",
    "r2_xgb_gpu = r2_score(y_test, y_pred_xgb_gpu)\n",
    "\n",
    "print(\"XGBoost GPU Metrics:\")\n",
    "print(f\"MSE: {mse_xgb_gpu:.4f}, MAE: {mae_xgb_gpu:.4f}, R²: {r2_xgb_gpu:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:23:16.732416Z",
     "iopub.status.busy": "2024-11-06T08:23:16.732034Z",
     "iopub.status.idle": "2024-11-06T08:23:39.872085Z",
     "shell.execute_reply": "2024-11-06T08:23:39.870450Z",
     "shell.execute_reply.started": "2024-11-06T08:23:16.732381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.052703 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 4.379723\n",
      "LightGBM GPU Metrics:\n",
      "MSE: 1.1747, MAE: 0.8198, R²: 0.4856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "# X, y = ... (Load your features and target variable)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train LightGBM Regressor with GPU\n",
    "lgb_regressor_gpu = lgb.LGBMRegressor(device='gpu')\n",
    "lgb_regressor_gpu.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate LightGBM\n",
    "y_pred_lgb_gpu = lgb_regressor_gpu.predict(X_test)\n",
    "mse_lgb_gpu = mean_squared_error(y_test, y_pred_lgb_gpu)\n",
    "mae_lgb_gpu = mean_absolute_error(y_test, y_pred_lgb_gpu)\n",
    "r2_lgb_gpu = r2_score(y_test, y_pred_lgb_gpu)\n",
    "\n",
    "print(\"LightGBM GPU Metrics:\")\n",
    "print(f\"MSE: {mse_lgb_gpu:.4f}, MAE: {mae_lgb_gpu:.4f}, R²: {r2_lgb_gpu:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:23:39.873605Z",
     "iopub.status.busy": "2024-11-06T08:23:39.873255Z",
     "iopub.status.idle": "2024-11-06T08:23:39.898484Z",
     "shell.execute_reply": "2024-11-06T08:23:39.895844Z",
     "shell.execute_reply.started": "2024-11-06T08:23:39.873567Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as impact_Score_xgb_regressor.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Save the trained model using pickle\n",
    "model_filename = 'impact_Score_xgb_regressor.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(xgb_regressor_gpu, file)\n",
    "\n",
    "print(f\"Model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:23:39.903293Z",
     "iopub.status.busy": "2024-11-06T08:23:39.902969Z",
     "iopub.status.idle": "2024-11-06T08:23:39.971590Z",
     "shell.execute_reply": "2024-11-06T08:23:39.970845Z",
     "shell.execute_reply.started": "2024-11-06T08:23:39.903259Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Output: 5.9000\n",
      "Predicted Output: 5.5671\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "with open(\"impact_Score_xgb_regressor.pkl\", 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Ensure y_test is a 1D NumPy array or pandas Series\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze()  # Convert DataFrame to Series if it's a single column\n",
    "\n",
    "# Select a random row from the test set\n",
    "random_index = np.random.randint(0, len(X_test))  # Select random index\n",
    "random_input = X_test.iloc[random_index].values.reshape(1, -1)  # Use .iloc for correct indexing\n",
    "real_output = y_test.iloc[random_index] if isinstance(y_test, pd.Series) else y_test[random_index]  # Access real output using .iloc\n",
    "\n",
    "# Predict the output using the loaded model\n",
    "predicted_output = loaded_model.predict(random_input)\n",
    "\n",
    "print(f\"Real Output: {real_output:.4f}\")\n",
    "print(f\"Predicted Output: {predicted_output[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASE SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:23:39.973419Z",
     "iopub.status.busy": "2024-11-06T08:23:39.972855Z",
     "iopub.status.idle": "2024-11-06T08:23:40.174933Z",
     "shell.execute_reply": "2024-11-06T08:23:40.173824Z",
     "shell.execute_reply.started": "2024-11-06T08:23:39.973383Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107087, 768)\n",
      "(107087,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with all the columns\n",
    "# Define columns to exclude\n",
    "columns_to_exclude = [\n",
    "    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n",
    "    'Published_Date', 'Last_Modified_Date', \n",
    "    'Access_Vector', 'Access_Complexity', \n",
    "    'Configurations', 'Reference_Data',\n",
    "    'Year', 'Base_Score', 'Exploitability_Score', \n",
    "    'Confidentiality_Impact', 'Integrity_Impact', \n",
    "    'Availability_Impact'\n",
    "]\n",
    "\n",
    "# Separate the target variable\n",
    "y = df['Base_Score']  # Your target variable\n",
    "\n",
    "# Select all columns except the excluded ones\n",
    "X = df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Check shapes\n",
    "print(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\n",
    "print(y.shape)  # Should show (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:23:40.176957Z",
     "iopub.status.busy": "2024-11-06T08:23:40.176502Z",
     "iopub.status.idle": "2024-11-06T08:23:51.182043Z",
     "shell.execute_reply": "2024-11-06T08:23:51.180888Z",
     "shell.execute_reply.started": "2024-11-06T08:23:40.176908Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost GPU Metrics:\n",
      "MSE: 1.4874, MAE: 0.9358, R²: 0.4681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "# X, y = ... (Load your features and target variable)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost Regressor with GPU\n",
    "xgb_regressor_gpu = xgb.XGBRegressor(tree_method='gpu_hist', gpu_id=0)\n",
    "xgb_regressor_gpu.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate XGBoost\n",
    "y_pred_xgb_gpu = xgb_regressor_gpu.predict(X_test)\n",
    "mse_xgb_gpu = mean_squared_error(y_test, y_pred_xgb_gpu)\n",
    "mae_xgb_gpu = mean_absolute_error(y_test, y_pred_xgb_gpu)\n",
    "r2_xgb_gpu = r2_score(y_test, y_pred_xgb_gpu)\n",
    "\n",
    "print(\"XGBoost GPU Metrics:\")\n",
    "print(f\"MSE: {mse_xgb_gpu:.4f}, MAE: {mae_xgb_gpu:.4f}, R²: {r2_xgb_gpu:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:23:51.183801Z",
     "iopub.status.busy": "2024-11-06T08:23:51.183457Z",
     "iopub.status.idle": "2024-11-06T08:24:14.293789Z",
     "shell.execute_reply": "2024-11-06T08:24:14.292486Z",
     "shell.execute_reply.started": "2024-11-06T08:23:51.183764Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.049063 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 6.439187\n",
      "LightGBM GPU Metrics:\n",
      "MSE: 1.5338, MAE: 0.9703, R²: 0.4515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "# X, y = ... (Load your features and target variable)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train LightGBM Regressor with GPU\n",
    "lgb_regressor_gpu = lgb.LGBMRegressor(device='gpu')\n",
    "lgb_regressor_gpu.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate LightGBM\n",
    "y_pred_lgb_gpu = lgb_regressor_gpu.predict(X_test)\n",
    "mse_lgb_gpu = mean_squared_error(y_test, y_pred_lgb_gpu)\n",
    "mae_lgb_gpu = mean_absolute_error(y_test, y_pred_lgb_gpu)\n",
    "r2_lgb_gpu = r2_score(y_test, y_pred_lgb_gpu)\n",
    "\n",
    "print(\"LightGBM GPU Metrics:\")\n",
    "print(f\"MSE: {mse_lgb_gpu:.4f}, MAE: {mae_lgb_gpu:.4f}, R²: {r2_lgb_gpu:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:24:14.296326Z",
     "iopub.status.busy": "2024-11-06T08:24:14.295697Z",
     "iopub.status.idle": "2024-11-06T08:24:14.308161Z",
     "shell.execute_reply": "2024-11-06T08:24:14.307314Z",
     "shell.execute_reply.started": "2024-11-06T08:24:14.296284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as base_score_xgb_regressor.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Save the trained model using pickle\n",
    "model_filename = 'base_score_xgb_regressor.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(xgb_regressor_gpu, file)\n",
    "\n",
    "print(f\"Model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:24:14.319049Z",
     "iopub.status.busy": "2024-11-06T08:24:14.309345Z",
     "iopub.status.idle": "2024-11-06T08:24:14.407982Z",
     "shell.execute_reply": "2024-11-06T08:24:14.407035Z",
     "shell.execute_reply.started": "2024-11-06T08:24:14.318996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Output: 9.9000\n",
      "Predicted Output: 7.7873\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "with open(\"base_score_xgb_regressor.pkl\", 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Ensure y_test has a reset index if necessary\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "# Select a random row from the test set\n",
    "random_index = np.random.randint(0, len(X_test))  # Select random index\n",
    "random_input = X_test.iloc[random_index].values.reshape(1, -1)  # Use .iloc and reshape for prediction\n",
    "real_output = y_test.iloc[random_index]  # Access real output using .iloc\n",
    "\n",
    "# Predict the output using the loaded model\n",
    "predicted_output = loaded_model.predict(random_input)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Real Output: {real_output:.4f}\")\n",
    "print(f\"Predicted Output: {predicted_output[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploitability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:24:14.412163Z",
     "iopub.status.busy": "2024-11-06T08:24:14.411133Z",
     "iopub.status.idle": "2024-11-06T08:24:14.620765Z",
     "shell.execute_reply": "2024-11-06T08:24:14.619701Z",
     "shell.execute_reply.started": "2024-11-06T08:24:14.412096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107087, 768)\n",
      "(107087,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with all the columns\n",
    "# Define columns to exclude\n",
    "columns_to_exclude = [\n",
    "    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n",
    "    'Published_Date', 'Last_Modified_Date', \n",
    "    'Access_Vector', 'Access_Complexity', \n",
    "    'Configurations', 'Reference_Data',\n",
    "    'Year', 'Base_Score', 'Exploitability_Score', \n",
    "    'Confidentiality_Impact', 'Integrity_Impact', \n",
    "    'Availability_Impact'\n",
    "]\n",
    "\n",
    "# Separate the target variable\n",
    "y = df['Exploitability_Score']  # Your target variable\n",
    "\n",
    "# Select all columns except the excluded ones\n",
    "X = df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Check shapes\n",
    "print(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\n",
    "print(y.shape)  # Should show (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:24:14.622240Z",
     "iopub.status.busy": "2024-11-06T08:24:14.621917Z",
     "iopub.status.idle": "2024-11-06T08:24:25.275535Z",
     "shell.execute_reply": "2024-11-06T08:24:25.274485Z",
     "shell.execute_reply.started": "2024-11-06T08:24:14.622207Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost GPU Metrics:\n",
      "MSE: 1.1731, MAE: 0.8116, R²: 0.4526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "# X, y = ... (Load your features and target variable)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost Regressor with GPU\n",
    "xgb_regressor_gpu = xgb.XGBRegressor(tree_method='gpu_hist', gpu_id=0)\n",
    "xgb_regressor_gpu.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate XGBoost\n",
    "y_pred_xgb_gpu = xgb_regressor_gpu.predict(X_test)\n",
    "mse_xgb_gpu = mean_squared_error(y_test, y_pred_xgb_gpu)\n",
    "mae_xgb_gpu = mean_absolute_error(y_test, y_pred_xgb_gpu)\n",
    "r2_xgb_gpu = r2_score(y_test, y_pred_xgb_gpu)\n",
    "\n",
    "print(\"XGBoost GPU Metrics:\")\n",
    "print(f\"MSE: {mse_xgb_gpu:.4f}, MAE: {mae_xgb_gpu:.4f}, R²: {r2_xgb_gpu:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:24:25.277048Z",
     "iopub.status.busy": "2024-11-06T08:24:25.276751Z",
     "iopub.status.idle": "2024-11-06T08:24:47.920898Z",
     "shell.execute_reply": "2024-11-06T08:24:47.919825Z",
     "shell.execute_reply.started": "2024-11-06T08:24:25.277016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.105714 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5.308553\n",
      "LightGBM GPU Metrics:\n",
      "MSE: 1.2120, MAE: 0.8494, R²: 0.4344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your dataset\n",
    "# X, y = ... (Load your features and target variable)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train LightGBM Regressor with GPU\n",
    "lgb_regressor_gpu = lgb.LGBMRegressor(device='gpu')\n",
    "lgb_regressor_gpu.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate LightGBM\n",
    "y_pred_lgb_gpu = lgb_regressor_gpu.predict(X_test)\n",
    "mse_lgb_gpu = mean_squared_error(y_test, y_pred_lgb_gpu)\n",
    "mae_lgb_gpu = mean_absolute_error(y_test, y_pred_lgb_gpu)\n",
    "r2_lgb_gpu = r2_score(y_test, y_pred_lgb_gpu)\n",
    "\n",
    "print(\"LightGBM GPU Metrics:\")\n",
    "print(f\"MSE: {mse_lgb_gpu:.4f}, MAE: {mae_lgb_gpu:.4f}, R²: {r2_lgb_gpu:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:24:47.922876Z",
     "iopub.status.busy": "2024-11-06T08:24:47.922480Z",
     "iopub.status.idle": "2024-11-06T08:24:47.939841Z",
     "shell.execute_reply": "2024-11-06T08:24:47.937706Z",
     "shell.execute_reply.started": "2024-11-06T08:24:47.922837Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as exploitability_Score_xgb_regressor.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model using pickle\n",
    "model_filename = 'exploitability_Score_xgb_regressor.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(xgb_regressor_gpu, file)\n",
    "\n",
    "print(f\"Model saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:24:47.941945Z",
     "iopub.status.busy": "2024-11-06T08:24:47.941349Z",
     "iopub.status.idle": "2024-11-06T08:24:48.025523Z",
     "shell.execute_reply": "2024-11-06T08:24:48.024482Z",
     "shell.execute_reply.started": "2024-11-06T08:24:47.941903Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Output: 5.7000\n",
      "Predicted Output: 5.7402\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "with open(\"exploitability_Score_xgb_regressor.pkl\", 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Reset the index of y_test to ensure it matches with X_test\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)  # Reset X_test index to ensure alignment\n",
    "\n",
    "# Select a random row from the test set\n",
    "random_index = np.random.randint(0, len(X_test))  # Select random index\n",
    "random_input = X_test.iloc[random_index].values.reshape(1, -1)  # Use .iloc for positional indexing\n",
    "real_output = y_test.iloc[random_index]  # Access real output using .iloc\n",
    "\n",
    "# Predict the output using the loaded model\n",
    "predicted_output = loaded_model.predict(random_input)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Real Output: {real_output:.4f}\")\n",
    "print(f\"Predicted Output: {predicted_output[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCESS COMPLEXITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:24:54.268029Z",
     "iopub.status.busy": "2024-11-06T08:24:54.267642Z",
     "iopub.status.idle": "2024-11-06T08:24:54.470581Z",
     "shell.execute_reply": "2024-11-06T08:24:54.469277Z",
     "shell.execute_reply.started": "2024-11-06T08:24:54.267992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107087, 768)\n",
      "(107087,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with all the columns\n",
    "# Define columns to exclude\n",
    "columns_to_exclude = [\n",
    "    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n",
    "    'Published_Date', 'Last_Modified_Date', \n",
    "    'Access_Vector', 'Access_Complexity', \n",
    "    'Configurations', 'Reference_Data',\n",
    "    'Year', 'Base_Score', 'Exploitability_Score', \n",
    "    'Confidentiality_Impact', 'Integrity_Impact', \n",
    "    'Availability_Impact'\n",
    "]\n",
    "\n",
    "# Separate the target variable\n",
    "y = df['Access_Complexity']  # Your target variable\n",
    "\n",
    "# Select all columns except the excluded ones\n",
    "X = df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Check shapes\n",
    "print(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\n",
    "print(y.shape)  # Should show (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:26:09.452891Z",
     "iopub.status.busy": "2024-11-06T08:26:09.452173Z",
     "iopub.status.idle": "2024-11-06T08:27:35.911395Z",
     "shell.execute_reply": "2024-11-06T08:27:35.910247Z",
     "shell.execute_reply.started": "2024-11-06T08:26:09.452851Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8496\n",
      "XGBoost Mean Squared Error: 0.1677\n",
      "XGBoost Mean Absolute Error: 0.1562\n",
      "\n",
      "CatBoost Accuracy: 0.8517\n",
      "CatBoost Mean Squared Error: 0.1670\n",
      "CatBoost Mean Absolute Error: 0.1545\n",
      "\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.049669 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -3.974878\n",
      "[LightGBM] [Info] Start training from score -0.544687\n",
      "[LightGBM] [Info] Start training from score -0.913307\n",
      "LightGBM Accuracy: 0.8383\n",
      "LightGBM Mean Squared Error: 0.1787\n",
      "LightGBM Mean Absolute Error: 0.1674\n",
      "\n",
      "Best model (CatBoost) saved with accuracy: 0.8517\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "\n",
    "# Encode categorical labels into numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the LabelEncoder as a pickle file\n",
    "with open(\"Access_Complexity_label_encoder.pkl\", 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Variables to store the best model and accuracy\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, model_name):\n",
    "    global best_model, best_accuracy, best_model_name\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"{model_name} Mean Absolute Error: {mae:.4f}\\n\")\n",
    "\n",
    "    # Update the best model if the current model has a higher accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = model_name\n",
    "\n",
    "# Initialize models with GPU support\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor', eval_metric='mlogloss', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(task_type='GPU', verbose=0, random_state=42),\n",
    "    'LightGBM': LGBMClassifier(device='gpu', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    train_and_evaluate(model, name)\n",
    "\n",
    "# Save the best model as a pickle file\n",
    "if best_model:\n",
    "    with open(f'Access_Complexity_best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:28:00.849026Z",
     "iopub.status.busy": "2024-11-06T08:28:00.847746Z",
     "iopub.status.idle": "2024-11-06T08:28:00.910753Z",
     "shell.execute_reply": "2024-11-06T08:28:00.909616Z",
     "shell.execute_reply.started": "2024-11-06T08:28:00.848939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label: LOW\n",
      "Predicted label: LOW\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model and label encoder\n",
    "with open(\"Access_Complexity_label_encoder.pkl\", 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"Access_Complexity_best_catboost_model.pkl\", 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "# Select a random sample from the test set\n",
    "random_index = np.random.randint(0, X_test.shape[0])\n",
    "random_sample = X_test[random_index:random_index + 1]\n",
    "\n",
    "# Predict the label for the sample (CatBoost requires data on CPU)\n",
    "predicted_label_encoded = best_model.predict(random_sample)\n",
    "\n",
    "# Convert the encoded prediction back to the original label\n",
    "predicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n",
    "\n",
    "# Get the actual label for the sample\n",
    "actual_label_encoded = y_test[random_index]\n",
    "actual_label = label_encoder.inverse_transform([actual_label_encoded])\n",
    "\n",
    "# Display the actual and predicted values\n",
    "print(f\"Actual label: {actual_label[0]}\")\n",
    "print(f\"Predicted label: {predicted_label[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:28:04.897369Z",
     "iopub.status.busy": "2024-11-06T08:28:04.896864Z",
     "iopub.status.idle": "2024-11-06T08:28:05.091688Z",
     "shell.execute_reply": "2024-11-06T08:28:05.090749Z",
     "shell.execute_reply.started": "2024-11-06T08:28:04.897332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107087, 768)\n",
      "(107087,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with all the columns\n",
    "# Define columns to exclude\n",
    "columns_to_exclude = [\n",
    "    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n",
    "    'Published_Date', 'Last_Modified_Date', \n",
    "    'Access_Vector', 'Access_Complexity', \n",
    "    'Configurations', 'Reference_Data',\n",
    "    'Year', 'Base_Score', 'Exploitability_Score', \n",
    "    'Confidentiality_Impact', 'Integrity_Impact', \n",
    "    'Availability_Impact'\n",
    "]\n",
    "\n",
    "# Separate the target variable\n",
    "y = df['Access_Vector']  # Your target variable\n",
    "\n",
    "# Select all columns except the excluded ones\n",
    "X = df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Check shapes\n",
    "print(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\n",
    "print(y.shape)  # Should show (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:30:12.414062Z",
     "iopub.status.busy": "2024-11-06T08:30:12.413281Z",
     "iopub.status.idle": "2024-11-06T08:31:31.490243Z",
     "shell.execute_reply": "2024-11-06T08:31:31.488015Z",
     "shell.execute_reply.started": "2024-11-06T08:30:12.414017Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9150\n",
      "XGBoost Mean Squared Error: 0.1281\n",
      "XGBoost Mean Absolute Error: 0.0994\n",
      "\n",
      "CatBoost Accuracy: 0.9153\n",
      "CatBoost Mean Squared Error: 0.1271\n",
      "CatBoost Mean Absolute Error: 0.0988\n",
      "\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.052736 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -3.818156\n",
      "[LightGBM] [Info] Start training from score -1.835068\n",
      "[LightGBM] [Info] Start training from score -0.200369\n",
      "LightGBM Accuracy: 0.9099\n",
      "LightGBM Mean Squared Error: 0.1333\n",
      "LightGBM Mean Absolute Error: 0.1045\n",
      "\n",
      "Best model (CatBoost) saved with accuracy: 0.9153\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "\n",
    "# Encode categorical labels into numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the LabelEncoder as a pickle file\n",
    "with open(\"Access_Vector_label_encoder.pkl\", 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Variables to store the best model and accuracy\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, model_name):\n",
    "    global best_model, best_accuracy, best_model_name\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"{model_name} Mean Absolute Error: {mae:.4f}\\n\")\n",
    "\n",
    "    # Update the best model if the current model has a higher accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = model_name\n",
    "\n",
    "# Initialize models with GPU support\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor', eval_metric='mlogloss', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(task_type='GPU', verbose=0, random_state=42),\n",
    "    'LightGBM': LGBMClassifier(device='gpu', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    train_and_evaluate(model, name)\n",
    "\n",
    "# Save the best model as a pickle file\n",
    "if best_model:\n",
    "    with open(f'accessVector_best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:31:43.220429Z",
     "iopub.status.busy": "2024-11-06T08:31:43.220002Z",
     "iopub.status.idle": "2024-11-06T08:31:43.278881Z",
     "shell.execute_reply": "2024-11-06T08:31:43.277936Z",
     "shell.execute_reply.started": "2024-11-06T08:31:43.220364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label: LOCAL\n",
      "Predicted label: LOCAL\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model and label encoder\n",
    "with open(\"Access_Vector_label_encoder.pkl\", 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"accessVector_best_catboost_model.pkl\", 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "# Select a random sample from the test set\n",
    "random_index = np.random.randint(0, X_test.shape[0])\n",
    "random_sample = X_test[random_index:random_index + 1]\n",
    "\n",
    "# Predict the label for the sample (CatBoost requires data on CPU)\n",
    "predicted_label_encoded = best_model.predict(random_sample)\n",
    "\n",
    "# Convert the encoded prediction back to the original label\n",
    "predicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n",
    "\n",
    "# Get the actual label for the sample\n",
    "actual_label_encoded = y_test[random_index]\n",
    "actual_label = label_encoder.inverse_transform([actual_label_encoded])\n",
    "\n",
    "# Display the actual and predicted values\n",
    "print(f\"Actual label: {actual_label[0]}\")\n",
    "print(f\"Predicted label: {predicted_label[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Availability Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:31:47.274422Z",
     "iopub.status.busy": "2024-11-06T08:31:47.273991Z",
     "iopub.status.idle": "2024-11-06T08:31:47.473124Z",
     "shell.execute_reply": "2024-11-06T08:31:47.472065Z",
     "shell.execute_reply.started": "2024-11-06T08:31:47.274384Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107087, 768)\n",
      "(107087,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with all the columns\n",
    "# Define columns to exclude\n",
    "columns_to_exclude = [\n",
    "    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n",
    "    'Published_Date', 'Last_Modified_Date', \n",
    "    'Access_Vector', 'Access_Complexity', \n",
    "    'Configurations', 'Reference_Data',\n",
    "    'Year', 'Base_Score', 'Exploitability_Score', \n",
    "    'Confidentiality_Impact', 'Integrity_Impact', \n",
    "    'Availability_Impact'\n",
    "]\n",
    "\n",
    "# Separate the target variable\n",
    "y = df['Availability_Impact']  # Your target variable\n",
    "\n",
    "# Select all columns except the excluded ones\n",
    "X = df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Check shapes\n",
    "print(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\n",
    "print(y.shape)  # Should show (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:32:37.084226Z",
     "iopub.status.busy": "2024-11-06T08:32:37.083421Z",
     "iopub.status.idle": "2024-11-06T08:33:57.136882Z",
     "shell.execute_reply": "2024-11-06T08:33:57.135350Z",
     "shell.execute_reply.started": "2024-11-06T08:32:37.084187Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8716\n",
      "XGBoost Mean Squared Error: 0.4591\n",
      "XGBoost Mean Absolute Error: 0.2387\n",
      "\n",
      "CatBoost Accuracy: 0.8729\n",
      "CatBoost Mean Squared Error: 0.4511\n",
      "CatBoost Mean Absolute Error: 0.2351\n",
      "\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.051445 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.535512\n",
      "[LightGBM] [Info] Start training from score -3.691556\n",
      "[LightGBM] [Info] Start training from score -0.942384\n",
      "LightGBM Accuracy: 0.8644\n",
      "LightGBM Mean Squared Error: 0.4850\n",
      "LightGBM Mean Absolute Error: 0.2521\n",
      "\n",
      "Best model (CatBoost) saved with accuracy: 0.8729\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "\n",
    "# Encode categorical labels into numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the LabelEncoder as a pickle file\n",
    "with open(\"Availability_Impact_label_encoder.pkl\", 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Variables to store the best model and accuracy\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, model_name):\n",
    "    global best_model, best_accuracy, best_model_name\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"{model_name} Mean Absolute Error: {mae:.4f}\\n\")\n",
    "\n",
    "    # Update the best model if the current model has a higher accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = model_name\n",
    "\n",
    "# Initialize models with GPU support\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor', eval_metric='mlogloss', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(task_type='GPU', verbose=0, random_state=42),\n",
    "    'LightGBM': LGBMClassifier(device='gpu', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    train_and_evaluate(model, name)\n",
    "\n",
    "# Save the best model as a pickle file\n",
    "if best_model:\n",
    "    with open(f'Availability_Impact_best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:33:57.140456Z",
     "iopub.status.busy": "2024-11-06T08:33:57.139511Z",
     "iopub.status.idle": "2024-11-06T08:33:57.211291Z",
     "shell.execute_reply": "2024-11-06T08:33:57.210060Z",
     "shell.execute_reply.started": "2024-11-06T08:33:57.140381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label: NONE\n",
      "Predicted label: NONE\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model and label encoder\n",
    "with open(\"Availability_Impact_label_encoder.pkl\", 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"Availability_Impact_best_catboost_model.pkl\", 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "# Select a random sample from the test set\n",
    "random_index = np.random.randint(0, X_test.shape[0])\n",
    "random_sample = X_test[random_index:random_index + 1]\n",
    "\n",
    "# Predict the label for the sample (CatBoost requires data on CPU)\n",
    "predicted_label_encoded = best_model.predict(random_sample)\n",
    "\n",
    "# Convert the encoded prediction back to the original label\n",
    "predicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n",
    "\n",
    "# Get the actual label for the sample\n",
    "actual_label_encoded = y_test[random_index]\n",
    "actual_label = label_encoder.inverse_transform([actual_label_encoded])\n",
    "\n",
    "# Display the actual and predicted values\n",
    "print(f\"Actual label: {actual_label[0]}\")\n",
    "print(f\"Predicted label: {predicted_label[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidentiality Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:33:57.214023Z",
     "iopub.status.busy": "2024-11-06T08:33:57.213187Z",
     "iopub.status.idle": "2024-11-06T08:33:57.423553Z",
     "shell.execute_reply": "2024-11-06T08:33:57.422529Z",
     "shell.execute_reply.started": "2024-11-06T08:33:57.213966Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107087, 768)\n",
      "(107087,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with all the columns\n",
    "# Define columns to exclude\n",
    "columns_to_exclude = [\n",
    "    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n",
    "    'Published_Date', 'Last_Modified_Date', \n",
    "    'Access_Vector', 'Access_Complexity', \n",
    "    'Configurations', 'Reference_Data',\n",
    "    'Year', 'Base_Score', 'Exploitability_Score', \n",
    "    'Confidentiality_Impact', 'Integrity_Impact', \n",
    "    'Availability_Impact'\n",
    "]\n",
    "\n",
    "# Separate the target variable\n",
    "y = df['Confidentiality_Impact']  # Your target variable\n",
    "\n",
    "# Select all columns except the excluded ones\n",
    "X = df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Check shapes\n",
    "print(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\n",
    "print(y.shape)  # Should show (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:33:57.425882Z",
     "iopub.status.busy": "2024-11-06T08:33:57.425552Z",
     "iopub.status.idle": "2024-11-06T08:35:19.659830Z",
     "shell.execute_reply": "2024-11-06T08:35:19.658781Z",
     "shell.execute_reply.started": "2024-11-06T08:33:57.425848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8406\n",
      "XGBoost Mean Squared Error: 0.4184\n",
      "XGBoost Mean Absolute Error: 0.2458\n",
      "\n",
      "CatBoost Accuracy: 0.8388\n",
      "CatBoost Mean Squared Error: 0.4199\n",
      "CatBoost Mean Absolute Error: 0.2475\n",
      "\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.048885 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.531989\n",
      "[LightGBM] [Info] Start training from score -1.638081\n",
      "[LightGBM] [Info] Start training from score -1.522288\n",
      "LightGBM Accuracy: 0.8240\n",
      "LightGBM Mean Squared Error: 0.4666\n",
      "LightGBM Mean Absolute Error: 0.2729\n",
      "\n",
      "Best model (XGBoost) saved with accuracy: 0.8406\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "\n",
    "# Encode categorical labels into numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the LabelEncoder as a pickle file\n",
    "with open(\"Confidentiality_Impact_label_encoder.pkl\", 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Variables to store the best model and accuracy\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, model_name):\n",
    "    global best_model, best_accuracy, best_model_name\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"{model_name} Mean Absolute Error: {mae:.4f}\\n\")\n",
    "\n",
    "    # Update the best model if the current model has a higher accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = model_name\n",
    "\n",
    "# Initialize models with GPU support\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor', eval_metric='mlogloss', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(task_type='GPU', verbose=0, random_state=42),\n",
    "    'LightGBM': LGBMClassifier(device='gpu', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    train_and_evaluate(model, name)\n",
    "\n",
    "# Save the best model as a pickle file\n",
    "if best_model:\n",
    "    with open(f'Confidentiality_Impact_best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:38:43.963044Z",
     "iopub.status.busy": "2024-11-06T08:38:43.962148Z",
     "iopub.status.idle": "2024-11-06T08:38:44.093834Z",
     "shell.execute_reply": "2024-11-06T08:38:44.093103Z",
     "shell.execute_reply.started": "2024-11-06T08:38:43.963005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label: HIGH\n",
      "Predicted label: HIGH\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model and label encoder\n",
    "with open(\"Confidentiality_Impact_label_encoder.pkl\", 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"Confidentiality_Impact_best_xgboost_model.pkl\", 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "# Select a random sample from the test set\n",
    "random_index = np.random.randint(0, X_test.shape[0])\n",
    "random_sample = X_test[random_index:random_index + 1]\n",
    "\n",
    "# Predict the label for the sample (CatBoost requires data on CPU)\n",
    "predicted_label_encoded = best_model.predict(random_sample)\n",
    "\n",
    "# Convert the encoded prediction back to the original label\n",
    "predicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n",
    "\n",
    "# Get the actual label for the sample\n",
    "actual_label_encoded = y_test[random_index]\n",
    "actual_label = label_encoder.inverse_transform([actual_label_encoded])\n",
    "\n",
    "# Display the actual and predicted values\n",
    "print(f\"Actual label: {actual_label[0]}\")\n",
    "print(f\"Predicted label: {predicted_label[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrity Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-06T08:35:20.366834Z",
     "iopub.status.idle": "2024-11-06T08:35:20.367270Z",
     "shell.execute_reply": "2024-11-06T08:35:20.367075Z",
     "shell.execute_reply.started": "2024-11-06T08:35:20.367054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame with all the columns\n",
    "# Define columns to exclude\n",
    "columns_to_exclude = [\n",
    "    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n",
    "    'Published_Date', 'Last_Modified_Date', \n",
    "    'Access_Vector', 'Access_Complexity', \n",
    "    'Configurations', 'Reference_Data',\n",
    "    'Year', 'Base_Score', 'Exploitability_Score', \n",
    "    'Confidentiality_Impact', 'Integrity_Impact', \n",
    "    'Availability_Impact'\n",
    "]\n",
    "\n",
    "# Separate the target variable\n",
    "y = df['Integrity_Impact']  # Your target variable\n",
    "\n",
    "# Select all columns except the excluded ones\n",
    "X = df.drop(columns=columns_to_exclude)\n",
    "\n",
    "# Check shapes\n",
    "print(X.shape)  # Should show (n_samples, n_features) where n_features should only include your embedding columns\n",
    "print(y.shape)  # Should show (n_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:35:33.842556Z",
     "iopub.status.busy": "2024-11-06T08:35:33.841747Z",
     "iopub.status.idle": "2024-11-06T08:36:54.433954Z",
     "shell.execute_reply": "2024-11-06T08:36:54.432926Z",
     "shell.execute_reply.started": "2024-11-06T08:35:33.842511Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8406\n",
      "XGBoost Mean Squared Error: 0.4184\n",
      "XGBoost Mean Absolute Error: 0.2458\n",
      "\n",
      "CatBoost Accuracy: 0.8388\n",
      "CatBoost Mean Squared Error: 0.4199\n",
      "CatBoost Mean Absolute Error: 0.2475\n",
      "\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 195840\n",
      "[LightGBM] [Info] Number of data points in the train set: 85669, number of used features: 768\n",
      "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 768 dense feature groups (62.75 MB) transferred to GPU in 0.051238 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.531989\n",
      "[LightGBM] [Info] Start training from score -1.638081\n",
      "[LightGBM] [Info] Start training from score -1.522288\n",
      "LightGBM Accuracy: 0.8240\n",
      "LightGBM Mean Squared Error: 0.4666\n",
      "LightGBM Mean Absolute Error: 0.2729\n",
      "\n",
      "Best model (XGBoost) saved with accuracy: 0.8406\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "\n",
    "# Encode categorical labels into numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the LabelEncoder as a pickle file\n",
    "with open(\"Integrity_Impact_label_encoder.pkl\", 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Variables to store the best model and accuracy\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "best_model_name = \"\"\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, model_name):\n",
    "    global best_model, best_accuracy, best_model_name\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"{model_name} Mean Absolute Error: {mae:.4f}\\n\")\n",
    "\n",
    "    # Update the best model if the current model has a higher accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = model_name\n",
    "\n",
    "# Initialize models with GPU support\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(tree_method='gpu_hist', predictor='gpu_predictor', eval_metric='mlogloss', random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(task_type='GPU', verbose=0, random_state=42),\n",
    "    'LightGBM': LGBMClassifier(device='gpu', random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    train_and_evaluate(model, name)\n",
    "\n",
    "# Save the best model as a pickle file\n",
    "if best_model:\n",
    "    with open(f'Integrity_Impact_best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    print(f\"Best model ({best_model_name}) saved with accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:39:34.366290Z",
     "iopub.status.busy": "2024-11-06T08:39:34.365864Z",
     "iopub.status.idle": "2024-11-06T08:39:34.502744Z",
     "shell.execute_reply": "2024-11-06T08:39:34.501996Z",
     "shell.execute_reply.started": "2024-11-06T08:39:34.366253Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label: LOW\n",
      "Predicted label: LOW\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model and label encoder\n",
    "with open(\"Integrity_Impact_label_encoder.pkl\", 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "with open(\"Integrity_Impact_best_xgboost_model.pkl\", 'rb') as f:\n",
    "    best_model = pickle.load(f)\n",
    "\n",
    "# Select a random sample from the test set\n",
    "random_index = np.random.randint(0, X_test.shape[0])\n",
    "random_sample = X_test[random_index:random_index + 1]\n",
    "\n",
    "# Predict the label for the sample (CatBoost requires data on CPU)\n",
    "predicted_label_encoded = best_model.predict(random_sample)\n",
    "\n",
    "# Convert the encoded prediction back to the original label\n",
    "predicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n",
    "\n",
    "# Get the actual label for the sample\n",
    "actual_label_encoded = y_test[random_index]\n",
    "actual_label = label_encoder.inverse_transform([actual_label_encoded])\n",
    "\n",
    "# Display the actual and predicted values\n",
    "print(f\"Actual label: {actual_label[0]}\")\n",
    "print(f\"Predicted label: {predicted_label[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Vulnerability Impact Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T08:41:17.097992Z",
     "iopub.status.busy": "2024-11-06T08:41:17.097014Z",
     "iopub.status.idle": "2024-11-06T08:41:23.280298Z",
     "shell.execute_reply": "2024-11-06T08:41:23.279485Z",
     "shell.execute_reply.started": "2024-11-06T08:41:17.097949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Outputs:\n",
      "Impact_Score: 3.6\n",
      "Base_Score: 6.949999999999999\n",
      "Exploitability_Score: 2.95\n",
      "Access_Complexity: MEDIUM\n",
      "Access_Vector: NETWORK\n",
      "Availability_Impact: HIGH\n",
      "Confidentiality_Impact: HIGH\n",
      "Integrity_Impact: HIGH\n",
      "\n",
      "Predicted Outputs:\n",
      "Impact_Score: 3.6547837257385254\n",
      "Base_Score: 6.902083396911621\n",
      "Exploitability_Score: 4.5355987548828125\n",
      "Access_Complexity: MEDIUM\n",
      "Access_Vector: NETWORK\n",
      "Availability_Impact: HIGH\n",
      "Confidentiality_Impact: HIGH\n",
      "Integrity_Impact: HIGH\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load your DataFrame\n",
    "# df = pd.read_csv('your_dataset.csv')  # Uncomment and specify your DataFrame source\n",
    "\n",
    "# Define columns to exclude\n",
    "columns_to_exclude = [\n",
    "    'Impact_Score', 'CVE_ID', 'ASSIGNER', 'Description', \n",
    "    'Published_Date', 'Last_Modified_Date', \n",
    "    'Access_Vector', 'Access_Complexity', \n",
    "    'Configurations', 'Reference_Data',\n",
    "    'Year', 'Base_Score', 'Exploitability_Score', \n",
    "    'Confidentiality_Impact', 'Integrity_Impact', \n",
    "    'Availability_Impact'\n",
    "]\n",
    "\n",
    "# List of target variables\n",
    "target_variables = [\n",
    "    'Impact_Score',\n",
    "    'Base_Score',\n",
    "    'Exploitability_Score',\n",
    "    'Access_Complexity',\n",
    "    'Access_Vector',\n",
    "    'Availability_Impact',\n",
    "    'Confidentiality_Impact',\n",
    "    'Integrity_Impact'\n",
    "]\n",
    "\n",
    "# Function to split dataset and return train-test splits\n",
    "def train_test_split_for_target(target):\n",
    "    # Separate the target variable\n",
    "    y = df[target]\n",
    "    \n",
    "    # Select all columns except the excluded ones\n",
    "    X = df.drop(columns=columns_to_exclude)\n",
    "    \n",
    "    # If the target is categorical, encode it\n",
    "    if target in ['Access_Complexity', 'Access_Vector', 'Availability_Impact', 'Confidentiality_Impact', 'Integrity_Impact']:\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(y)\n",
    "        return train_test_split(X, y, test_size=0.2, random_state=42), label_encoder  # Return encoder for later use\n",
    "    else:\n",
    "        return train_test_split(X, y, test_size=0.2, random_state=42), None\n",
    "\n",
    "# Load regression models\n",
    "regression_models = {\n",
    "    \"Impact_Score\": \"impact_Score_xgb_regressor.pkl\",\n",
    "    \"Base_Score\": \"base_score_xgb_regressor.pkl\",\n",
    "    \"Exploitability_Score\": \"exploitability_Score_xgb_regressor.pkl\"\n",
    "}\n",
    "\n",
    "# Load classification models and label encoders\n",
    "classification_models = {\n",
    "    \"Access_Complexity\": (\"Access_Complexity_best_catboost_model.pkl\", \"Access_Complexity_label_encoder.pkl\"),\n",
    "    \"Access_Vector\": (\"accessVector_best_catboost_model.pkl\", \"Access_Vector_label_encoder.pkl\"),\n",
    "    \"Availability_Impact\": (\"Availability_Impact_best_catboost_model.pkl\", \"Availability_Impact_label_encoder.pkl\"),\n",
    "    \"Confidentiality_Impact\": (\"Confidentiality_Impact_best_xgboost_model.pkl\", \"Confidentiality_Impact_label_encoder.pkl\"),\n",
    "    \"Integrity_Impact\": (\"Integrity_Impact_best_xgboost_model.pkl\", \"Integrity_Impact_label_encoder.pkl\"),\n",
    "}\n",
    "\n",
    "# Initialize dictionaries to hold actual and predicted values\n",
    "actual_outputs = {}\n",
    "predicted_outputs = {}\n",
    "\n",
    "# Loop through all target variables to get train-test splits and make predictions\n",
    "for target in target_variables:\n",
    "    (X_train, X_test, y_train, y_test), label_encoder = train_test_split_for_target(target)\n",
    "\n",
    "    # Reset index of y_test and X_test if necessary\n",
    "    y_test = pd.Series(y_test).reset_index(drop=True)\n",
    "    X_test = pd.DataFrame(X_test).reset_index(drop=True)\n",
    "\n",
    "    # Select a random row from the test set\n",
    "    random_index = np.random.randint(0, len(X_test))\n",
    "    random_input = X_test.iloc[random_index].values.reshape(1, -1)\n",
    "\n",
    "    # Predict for regression models\n",
    "    if target in regression_models.keys():\n",
    "        model_file = regression_models[target]\n",
    "        with open(model_file, 'rb') as file:\n",
    "            loaded_model = pickle.load(file)\n",
    "        real_output = y_test.iloc[random_index]\n",
    "        predicted_output = loaded_model.predict(random_input)\n",
    "        actual_outputs[target] = real_output\n",
    "        predicted_outputs[target] = predicted_output[0]\n",
    "\n",
    "    # Predict for classification models\n",
    "    elif target in classification_models.keys():\n",
    "        model_file, encoder_file = classification_models[target]\n",
    "        with open(encoder_file, 'rb') as f:\n",
    "            label_encoder = pickle.load(f)\n",
    "        with open(model_file, 'rb') as f:\n",
    "            best_model = pickle.load(f)\n",
    "\n",
    "        predicted_label_encoded = best_model.predict(random_input)\n",
    "        predicted_label = label_encoder.inverse_transform(predicted_label_encoded.astype(int))\n",
    "        actual_label_encoded = y_test.iloc[random_index]\n",
    "        actual_label = label_encoder.inverse_transform([actual_label_encoded])\n",
    "\n",
    "        actual_outputs[target] = actual_label[0]\n",
    "        predicted_outputs[target] = predicted_label[0]\n",
    "\n",
    "# Display actual and predicted values for all outputs\n",
    "print(\"Actual Outputs:\")\n",
    "for key, value in actual_outputs.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nPredicted Outputs:\")\n",
    "for key, value in predicted_outputs.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6003234,
     "sourceId": 9795944,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 155021,
     "modelInstanceId": 132223,
     "sourceId": 155602,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
